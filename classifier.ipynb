{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import preprocess"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T02:51:50.207449Z",
     "start_time": "2023-12-10T02:51:50.203324Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static data:\n",
      "                                                                                                                                                                                                                                                                                                                         words  \\\n",
      "0                                                                                                                                                                                                                                                                  [anyway, ,, thanks, mkm, and, keep, up, the, good, work, !]   \n",
      "1                                                                                                                                                                                                                                                    [well, done, steffi, —, keep, up, the, good, work, and, keep, winning, .]   \n",
      "2                                                                                                                                                                                           [please, use, it, as, a, reminder, to, ensure, that, you, keep, up, the, good, work, and, the, resolutions, you, have, started, .]   \n",
      "3                                                                                                                                                                                                                                                                                   [please, do, keep, up, the, good, work, .]   \n",
      "4  [we, hope, you, find, the, current, issue, still, of, interest, and, we, plan, to, keep, up, the, good, work, during, the, coming, year, seeking, out, happenings/events/, stories, to, retell, for, you, ,, but, as, it, is, your, newspaper, do, contact, us, with, your, own, ideas, and, suggestions, at, any, time, .]   \n",
      "\n",
      "                                                                                                                                                                                      tags  \\\n",
      "0                                                                                                                          [O, O, O, O, O, B-IDIOM, I-IDIOM, I-IDIOM, I-IDIOM, I-IDIOM, O]   \n",
      "1                                                                                                                    [O, O, O, O, B-IDIOM, I-IDIOM, I-IDIOM, I-IDIOM, I-IDIOM, O, O, O, O]   \n",
      "2                                                                                         [O, O, O, O, O, O, O, O, O, O, B-IDIOM, I-IDIOM, I-IDIOM, I-IDIOM, I-IDIOM, O, O, O, O, O, O, O]   \n",
      "3                                                                                                                                   [O, O, B-IDIOM, I-IDIOM, I-IDIOM, I-IDIOM, I-IDIOM, O]   \n",
      "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-IDIOM, I-IDIOM, I-IDIOM, I-IDIOM, I-IDIOM, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
      "\n",
      "               candidate  label  \n",
      "0  keep up the good work      1  \n",
      "1  keep up the good work      1  \n",
      "2  keep up the good work      1  \n",
      "3  keep up the good work      1  \n",
      "4  keep up the good work      1  \n",
      "Formal data:\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                    words  \\\n",
      "0                                                                                                                                                                                                                                                                                                                                                      [‘, you, know, ,, the, panda, who, keeps, an, eye, on, my, drinking, habits, ., ’]   \n",
      "1                                                                                                                                                                                                                                                                                                                                                                               [but, i, will, also, be, keeping, an, eye, on, you, ., ’]   \n",
      "2                                                                                                                                                                                                                                                                                                                                                                          [‘, i, will, keep, an, eye, on, him, ,, ’, reassured, jack, .]   \n",
      "3  [moreover, ,, international, operations, director, richard, ferry, claims, that, the, bracknell, ,, berkshire-based, company, 's, services, are, unique, —, although, most, rivals, can, offer, centralised, expertise, ,, he, says, ,, no-one, else, can, monitor, computer, systems, remotely, ,, or, keep, an, eye, on, such, critical, issues, as, temperature, and, air, conditioning, levels, at, any, given, customer, site, .]   \n",
      "4                                                                                                                                                                                                                                         [once, duncan, had, managed, to, fire, off, a, report, and, stop, his, watch-replacement, from, stumbling, on, the, terrorists, ,, he, had, settled, down, to, keep, an, eye, on, the, gang, .]   \n",
      "\n",
      "                                                                                                                                                                                                     tags  \\\n",
      "0                                                                                                                                [O, O, O, O, O, O, O, B-IDIOM, I-IDIOM, I-IDIOM, I-IDIOM, O, O, O, O, O]   \n",
      "1                                                                                                                                            [O, O, O, O, O, B-IDIOM, I-IDIOM, I-IDIOM, I-IDIOM, O, O, O]   \n",
      "2                                                                                                                                         [O, O, O, B-IDIOM, I-IDIOM, I-IDIOM, I-IDIOM, O, O, O, O, O, O]   \n",
      "3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-IDIOM, I-IDIOM, I-IDIOM, I-IDIOM, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
      "4                                                                                   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-IDIOM, I-IDIOM, I-IDIOM, I-IDIOM, O, O, O]   \n",
      "\n",
      "            candidate  label  \n",
      "0  keep [pron] eye on      1  \n",
      "1  keep [pron] eye on      1  \n",
      "2  keep [pron] eye on      1  \n",
      "3  keep [pron] eye on      1  \n",
      "4  keep [pron] eye on      1  \n"
     ]
    }
   ],
   "source": [
    "static_df, formal_df = preprocess.fetch_preprocessed_data()\n",
    "print(\"Static data:\")\n",
    "print(static_df.head())\n",
    "print(\"Formal data:\")\n",
    "print(formal_df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T02:51:52.456191Z",
     "start_time": "2023-12-10T02:51:52.072918Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "label\n1    2761\n0     375\nName: count, dtype: int64"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formal_df[\"label\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T00:42:48.830531Z",
     "start_time": "2023-12-10T00:42:48.825729Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11957908163265306\n"
     ]
    }
   ],
   "source": [
    "print(375 / (375 + 2761))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T00:42:49.939518Z",
     "start_time": "2023-12-10T00:42:49.930186Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The formal dataset contains 12% literal uses and 88% idiomatic uses. The static dataset only contains idiomatic uses. For the first experiment, we will train a classifier on the formal dataset to determine whether a sentence is formal or idiomatic."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "# Concatenate the words into a single string for each sample\n",
    "formal_df['text'] = formal_df['words'].apply(lambda x: ' '.join(x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T00:42:54.859670Z",
     "start_time": "2023-12-10T00:42:54.855048Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    2209\n",
      "0     299\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Random Forest Scores:\n",
      "accuracy: Mean=0.89, Std=0.00\n",
      "precision_macro: Mean=0.83, Std=0.08\n",
      "recall_macro: Mean=0.54, Std=0.01\n",
      "f1_macro: Mean=0.54, Std=0.02\n",
      "\n",
      "\n",
      "SVM Scores:\n",
      "accuracy: Mean=0.89, Std=0.00\n",
      "precision_macro: Mean=0.80, Std=0.04\n",
      "recall_macro: Mean=0.53, Std=0.01\n",
      "f1_macro: Mean=0.53, Std=0.02\n",
      "\n",
      "\n",
      "Logistic Regression Scores:\n",
      "accuracy: Mean=0.87, Std=0.02\n",
      "precision_macro: Mean=0.68, Std=0.04\n",
      "recall_macro: Mean=0.66, Std=0.03\n",
      "f1_macro: Mean=0.67, Std=0.04\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_formal = formal_df[\"text\"]\n",
    "y_formal = formal_df[\"label\"]\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train_formal, X_test_formal, y_train_formal, y_test_formal = train_test_split(X_formal, y_formal, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the class distribution before resampling\n",
    "print(pd.Series(y_train_formal).value_counts())\n",
    "print()\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "\n",
    "# Initialize classifiers\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "svm_clf = SVC(random_state=42)\n",
    "lr_clf = LogisticRegression(random_state=42)\n",
    "\n",
    "# Create a pipeline that first vectorizes the text and then oversamples the minority class before training\n",
    "# Note: Oversampling and vectorization are done inside the cross-validation loop to avoid data leakage\n",
    "rf_pipeline = Pipeline([\n",
    "    ('tfidf', vectorizer),\n",
    "    ('oversample', RandomOverSampler(random_state=42)),\n",
    "    ('classifier', rf_clf)\n",
    "])\n",
    "\n",
    "svm_pipeline = Pipeline([\n",
    "    ('tfidf', vectorizer),\n",
    "    ('oversample', RandomOverSampler(random_state=42)),\n",
    "    ('classifier', svm_clf)\n",
    "])\n",
    "\n",
    "lr_pipeline = Pipeline([\n",
    "    ('tfidf', vectorizer),\n",
    "    ('oversample', RandomOverSampler(random_state=42)),\n",
    "    ('classifier', lr_clf)\n",
    "])\n",
    "\n",
    "# Create a dictionary of pipelines and classifier types for ease of reference\n",
    "pipelines = {\n",
    "    \"Random Forest\": rf_pipeline,\n",
    "    \"SVM\": svm_pipeline,\n",
    "    \"Logistic Regression\": lr_pipeline\n",
    "}\n",
    "\n",
    "scoring_metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "\n",
    "# Perform 5-fold cross-validation and print the results\n",
    "for classifier_name, pipeline in pipelines.items():\n",
    "    scores = cross_validate(pipeline, X_train_formal, y_train_formal, cv=5, scoring=scoring_metrics)\n",
    "    print(f'{classifier_name} Scores:')\n",
    "    for metric_name in scoring_metrics:\n",
    "        metric_scores = scores[f'test_{metric_name}']\n",
    "        print(f'{metric_name}: Mean={metric_scores.mean():.2f}, Std={metric_scores.std():.2f}')\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T00:43:07.669231Z",
     "start_time": "2023-12-10T00:42:59.388231Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "# Vectorize the data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train_formal)\n",
    "X_test_vectorized = vectorizer.transform(X_test_formal)\n",
    "\n",
    "# Fit the models on the training set\n",
    "rf_clf.fit(X_train_vectorized, y_train_formal)\n",
    "svm_clf.fit(X_train_vectorized, y_train_formal)\n",
    "lr_clf.fit(X_train_vectorized, y_train_formal)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_clf.predict(X_test_vectorized)\n",
    "y_pred_svm = svm_clf.predict(X_test_vectorized)\n",
    "y_pred_lr = lr_clf.predict(X_test_vectorized)\n",
    "\n",
    "# Calculate the confusion matrices\n",
    "conf_matrix_rf = confusion_matrix(y_test_formal, y_pred_rf)\n",
    "conf_matrix_svm = confusion_matrix(y_test_formal, y_pred_svm)\n",
    "conf_matrix_lr = confusion_matrix(y_test_formal, y_pred_lr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T00:43:20.253381Z",
     "start_time": "2023-12-10T00:43:18.737056Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Random Forest:\n",
      "[[ 10  66]\n",
      " [  4 548]]\n",
      "\n",
      "Confusion Matrix for SVM:\n",
      "[[  3  73]\n",
      " [  1 551]]\n",
      "\n",
      "Confusion Matrix for Logistic Regression:\n",
      "[[  2  74]\n",
      " [  0 552]]\n"
     ]
    }
   ],
   "source": [
    "# Print the confusion matrices\n",
    "print(\"Confusion Matrix for Random Forest:\")\n",
    "print(conf_matrix_rf)\n",
    "print(\"\\nConfusion Matrix for SVM:\")\n",
    "print(conf_matrix_svm)\n",
    "print(\"\\nConfusion Matrix for Logistic Regression:\")\n",
    "print(conf_matrix_lr)\n",
    "\n",
    "# Note: The confusion matrix format is\n",
    "# [[true_negative, false_positive],\n",
    "#  [false_negative, true_positive]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T00:43:20.773535Z",
     "start_time": "2023-12-10T00:43:20.767572Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "data": {
      "text/plain": "label\n1    552\n0     76\nName: count, dtype: int64"
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_formal.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T02:46:51.739600Z",
     "start_time": "2023-12-10T02:46:51.733244Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "All the models substantially underpredicted the negative samples. The random forest classifier predicted the most negative samples, but it still had a reasonably high error rate even for the ones it did predict as negative - only 10 out of the 14 samples it predicted as negative were actually negative."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "# Extract false positives and false negatives for analysis\n",
    "fp_rf = (y_pred_rf == 1) & (y_test_formal == 0)\n",
    "fn_rf = (y_pred_rf == 0) & (y_test_formal == 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T02:46:53.943122Z",
     "start_time": "2023-12-10T02:46:53.938353Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "data": {
      "text/plain": "              candidate  \\\n2711    tie [pron] knot   \n291             bad egg   \n325     be in hot water   \n2279  lose [pron] touch   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                              text  \n2711                                                                                                                                                                                                                                                                                                                                                                                                          stefan ties the knot  \n291                                                                                                                                                                                                                                                                                                                                                                                                              he 's a bad egg .  \n325   i 'm in hot water over various things — nothing important enough to bore you with , but i know the director wants shot of me — he 's said as much and i 'm sure my days are numbered ; i feel like i 'm struggling to keep my head above water — oh , i knew this particular pool was going to be deep , but he 's there waiting just above the surface to shove me under , finding some half-baked reason to be rid of me .  \n2279                                                                                                                                                                                                                                                                well away from the beaten track he laid her gently on a bed of moss and bracken , and she opened her arms to him , loath to lose his touch for even a second .  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>candidate</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2711</th>\n      <td>tie [pron] knot</td>\n      <td>stefan ties the knot</td>\n    </tr>\n    <tr>\n      <th>291</th>\n      <td>bad egg</td>\n      <td>he 's a bad egg .</td>\n    </tr>\n    <tr>\n      <th>325</th>\n      <td>be in hot water</td>\n      <td>i 'm in hot water over various things — nothing important enough to bore you with , but i know the director wants shot of me — he 's said as much and i 'm sure my days are numbered ; i feel like i 'm struggling to keep my head above water — oh , i knew this particular pool was going to be deep , but he 's there waiting just above the surface to shove me under , finding some half-baked reason to be rid of me .</td>\n    </tr>\n    <tr>\n      <th>2279</th>\n      <td>lose [pron] touch</td>\n      <td>well away from the beaten track he laid her gently on a bed of moss and bracken , and she opened her arms to him , loath to lose his touch for even a second .</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain the samples corresponding to the false positives and false negatives from the original dataset\n",
    "false_positives_rf = formal_df.iloc[fp_rf[fp_rf].index].drop(columns=[\"words\", \"tags\", \"label\"], axis=1)\n",
    "false_negatives_rf = formal_df.iloc[fn_rf[fn_rf].index].drop(columns=[\"words\", \"tags\", \"label\"], axis=1)\n",
    "false_negatives_rf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T02:46:24.875427Z",
     "start_time": "2023-12-10T02:46:24.870945Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some false positive samples for Random Forest:\n",
      "- 1791: adding fuel to the fire is deepa kaur , the daughter of rajah man singh , the maharajah 's late brother . (add fuel to [pron] fire)\n",
      "- 449: paul bit his lip as he jogged at his father 's shoulder along a trail that wound through fringes of jungle beside the la nga river . (bite [pron] lip)\n",
      "- 1146: so as i can take her for a ride and back . (take for [pron] ride)\n",
      "- 567: candles were brought to the tables and any mishaps in the food or service were blamed on the lack of power , which lasted for three hours . (bring to [pron] table)\n",
      "- 2922: keep them cool (keep [pron] cool)\n",
      "- 2124: your partner standing behind you , pulls your leg towards him gently . (pull [pron] leg)\n",
      "- 1814: the axeman wore the first beard of a boy and had big ears that stuck through his hair . (have big ears)\n",
      "- 2285: ‘ good , ’ said caspar , meaning it , and fenella , still curled into her uncomfortable corner , crossed her fingers and tried not to disturb the shining folds of the robes all about her . (cross [pron] fingers)\n",
      "- 1159: you have never taken us on a ride on your motorbike this year . (take for [pron] ride)\n",
      "- 433: so please , please could you tell the people concerned ( martin ‘ i down everything ’ hill and ross ‘ i have an extremely big head ’ nicholls ) that the c64 is not crap at all , in fact it 's very very good ! (big head)\n",
      "\n",
      "Some false negative samples for Random Forest:\n",
      "- 2711: stefan ties the knot (tie [pron] knot)\n",
      "- 291: he 's a bad egg . (bad egg)\n",
      "- 325: i 'm in hot water over various things — nothing important enough to bore you with , but i know the director wants shot of me — he 's said as much and i 'm sure my days are numbered ; i feel like i 'm struggling to keep my head above water — oh , i knew this particular pool was going to be deep , but he 's there waiting just above the surface to shove me under , finding some half-baked reason to be rid of me . (be in hot water)\n",
      "- 2279: well away from the beaten track he laid her gently on a bed of moss and bracken , and she opened her arms to him , loath to lose his touch for even a second . (lose [pron] touch)\n"
     ]
    }
   ],
   "source": [
    "def format_samples(samples_series):\n",
    "    return \"\\n\".join([f\"- {i}: {sample['text']} ({sample['candidate']})\" for i, sample in samples_series.iterrows()])\n",
    "\n",
    "# Print some of the false positives and false negatives for Random Forest\n",
    "print(\"Some false positive samples for Random Forest:\")\n",
    "print(format_samples(false_positives_rf.head(n=10)))\n",
    "\n",
    "print(\"\\nSome false negative samples for Random Forest:\")\n",
    "print(format_samples(false_negatives_rf.head(n=10)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T02:47:39.213185Z",
     "start_time": "2023-12-10T02:47:39.210403Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "data": {
      "text/plain": "label\n1    21891\nName: count, dtype: int64"
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_df[\"label\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T02:47:43.448228Z",
     "start_time": "2023-12-10T02:47:43.445243Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Taking a closer look at these samples, we learn some important pieces of information:\n",
    "- Some of the samples are mislabeled. For example, index 1791 is an idiomatic usage of the phrase \"add fuel to the fire,\" but the sentence is labeled `0`. Index 2279 is a literal usage of the phrase \"lose one's touch,\" but it is labeled as `1`. Even though the labels for these samples are incorrect, `translated_sentences.txt` has the correct translations for them. According to the paper, \"These labels are done by automatic systems with high accuracy.\" The paper does not mention the source of the translated sentences. The original sentences are taken from StringNet, which is a knowledge base containing n-grams extracted from the British National Corpus (http://nav.stringnet.org/about.php). From looking at the StringNet Navigator, it's unclear if the translated sentences could have come from there.\n",
    "- For some of the samples, it's hard to tell if a particular phrase is used idiomatically or literally due to the lack of context. For example, the sample at index 2711 is simply \"Stefan ties the knot.\" This could be referring to getting married, which would be the idiomatic sense of the phrase, or it could be referring to literally tying a knot (in a piece of rope or similar). Unfortunately, the dataset does not provide the context in which a sentence occurs, and going to the original source of the sentences (StringNet) does not provide any additional help in determining the context of a phrase, as mentioned above.\n",
    "\n",
    "Due to these challenges, as well as the fact that the dataset contains a relatively small number of sentences with literal uses of phrases (375 negative samples of sentences with formal idioms; 2761 positive samples of sentences with formal idioms; 21891 samples of static idioms, all of which are positive), we will focus on sequence labeling for the remainder of this report. The dataset has more data that is suitable for sequence labeling than for idiom classification. Additionally, the original study that published the data discusses its potential utility in sequence labeling and trains a sequence labeling on the dataset, which can be used as a benchmark for our sequence labeling model."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
